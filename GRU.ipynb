{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNojAvSXXf4i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torch.utils.data import DataLoader\n",
        "from torchaudio.datasets import LIBRISPEECH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvvTOcE0X7dt"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SAMPLE_RATE = 16000\n",
        "N_MFCC = 13\n",
        "N_MELS = 80\n",
        "BLANK_ID = 0\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgux27p6X_q9"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 2) Vocab & encodage\n",
        "# =========================\n",
        "# LibriSpeech contient typiquement des majuscules et apostrophes, on normalise en minuscules\n",
        "# et on restreint à espace + apostrophe + a..z.\n",
        "VOCAB = [\" \", \"'\"] + [chr(i) for i in range(97, 123)]  # \" \", \"'\", a..z\n",
        "char2id = {c: i + 1 for i, c in enumerate(VOCAB)}      # 1.. (0 = blank)\n",
        "id2char = {i + 1: c for i, c in enumerate(VOCAB)}\n",
        "\n",
        "def normalize_text(txt: str) -> str:\n",
        "    txt = txt.lower()\n",
        "    return \"\".join(ch for ch in txt if ch in char2id)\n",
        "\n",
        "def text_to_int(txt: str):\n",
        "    return [char2id[ch] for ch in normalize_text(txt)]\n",
        "\n",
        "def int_to_text(ids):\n",
        "    return \"\".join(id2char[i] for i in ids if i in id2char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wATVHXw6YDf1"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 3) MFCC & resample\n",
        "# =========================\n",
        "mfcc_transform = torchaudio.transforms.MFCC(\n",
        "    sample_rate=SAMPLE_RATE,\n",
        "    n_mfcc=N_MFCC,\n",
        "    melkwargs={\"n_fft\": 400, \"hop_length\": 160, \"n_mels\": 40, \"center\": False},\n",
        ")\n",
        "\n",
        "_resamplers = {}\n",
        "def maybe_resample(waveform: torch.Tensor, sr: int) -> torch.Tensor:\n",
        "    if sr == SAMPLE_RATE:\n",
        "        return waveform\n",
        "    # Cache du resampler par sr d’origine\n",
        "    if sr not in _resamplers:\n",
        "        _resamplers[sr] = torchaudio.transforms.Resample(orig_freq=sr, new_freq=SAMPLE_RATE)\n",
        "    return _resamplers[sr](waveform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juNVyDphPzYf"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 3) Bi-directional GRU\n",
        "# =========================\n",
        "class BidirGRU_CTC(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, num_layers=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True, # bidirectional pour savoir determiner a partir de ce qui vient apres\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (batch, seq_len, input_size)\n",
        "        \"\"\"\n",
        "\n",
        "        out, _ = self.gru(x)\n",
        "\n",
        "        out = self.dropout(out)\n",
        "        logits = self.fc(out)\n",
        "\n",
        "        logits = logits.transpose(0, 1)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5fUmHr7YKTz"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 5) Collate function\n",
        "# =========================\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    batch: list of tuples (waveform, sample_rate, transcript, speaker_id, chapter_id, utterance_id)\n",
        "    Retour:\n",
        "      - features: (B, T_max, F)\n",
        "      - input_lengths: (B,)\n",
        "      - targets_concat: (sum_S,)\n",
        "      - target_lengths: (B,)\n",
        "      - texts: liste des textes normalisés (debug/affichage)\n",
        "    \"\"\"\n",
        "    feats_list = []\n",
        "    input_lengths = []\n",
        "    targets = []\n",
        "    target_lengths = []\n",
        "    texts = []\n",
        "\n",
        "    for waveform, sr, transcript, *_ in batch:\n",
        "        # waveform: (channels, time) -> mono\n",
        "        if waveform.dim() == 2:\n",
        "            waveform = waveform.mean(dim=0)  # (time,)\n",
        "        else:\n",
        "            waveform = waveform.squeeze(0)   # (time,)\n",
        "\n",
        "        # Resample si besoin\n",
        "        waveform = maybe_resample(waveform, int(sr))\n",
        "\n",
        "        # MFCC: entrée 1D -> sortie (n_mfcc, time), puis transpose -> (time, n_mfcc)\n",
        "        mfcc = mfcc_transform(waveform)      # (n_mfcc, time)\n",
        "        if mfcc.dim() == 3:                  # sécurité si un canal subsiste\n",
        "            mfcc = mfcc.squeeze(0)           # (n_mfcc, time)\n",
        "        feat = mfcc.transpose(0, 1).contiguous()  # (time, n_mfcc)\n",
        "\n",
        "        feats_list.append(feat)\n",
        "        input_lengths.append(feat.shape[0])\n",
        "\n",
        "        norm_txt = normalize_text(transcript)\n",
        "        y = torch.tensor(text_to_int(norm_txt), dtype=torch.long)\n",
        "        targets.append(y)\n",
        "        target_lengths.append(len(y))\n",
        "        texts.append(norm_txt)\n",
        "\n",
        "    # Padding temporel pour empiler en batch-first\n",
        "    # feats_list: list de (T_i, F) -> (B, T_max, F)\n",
        "    F = feats_list[0].shape[1]\n",
        "    T_max = max(t.shape[0] for t in feats_list)\n",
        "    padded = torch.zeros(len(feats_list), T_max, F, dtype=feats_list[0].dtype)\n",
        "    for i, f in enumerate(feats_list):\n",
        "        padded[i, : f.shape[0]] = f\n",
        "\n",
        "    features = padded\n",
        "    input_lengths = torch.tensor(input_lengths, dtype=torch.long)\n",
        "    targets_concat = torch.cat(targets) if len(targets) > 0 else torch.empty(0, dtype=torch.long)\n",
        "    target_lengths = torch.tensor(target_lengths, dtype=torch.long)\n",
        "\n",
        "    return features, input_lengths, targets_concat, target_lengths, texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCmPJ03oYRKR"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 6) Greedy CTC decode\n",
        "# =========================\n",
        "def greedy_ctc_decode(log_probs: torch.Tensor, input_lengths: torch.Tensor):\n",
        "    \"\"\"\n",
        "    log_probs: (T, B, C)\n",
        "    input_lengths: (B,)\n",
        "    \"\"\"\n",
        "    max_ids = log_probs.argmax(dim=-1)  # (T, B)\n",
        "    T, B = max_ids.shape\n",
        "    results = []\n",
        "    for b in range(B):\n",
        "        prev = None\n",
        "        seq = []\n",
        "        for t in range(int(input_lengths[b].item())):\n",
        "            p = int(max_ids[t, b].item())\n",
        "            if p != BLANK_ID and p != prev:\n",
        "                seq.append(p)\n",
        "            prev = p\n",
        "        results.append(int_to_text(seq))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U1HiUSvYU4N"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 7) Entraînement\n",
        "# =========================\n",
        "def train_one_epoch(model, loader, optimizer, criterion, epoch, log_interval=50, grad_clip=5.0):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    for step, (features, input_lengths, targets_concat, target_lengths, texts) in enumerate(loader, 1):\n",
        "        features = features.to(DEVICE)            # (B, T, F)\n",
        "        input_lengths = input_lengths.to(DEVICE)  # (B,)\n",
        "        targets_concat = targets_concat.to(DEVICE)  # (sum_S,)\n",
        "        target_lengths = target_lengths.to(DEVICE)  # (B,)\n",
        "\n",
        "        logits = model(features)                 # (T, B, C)\n",
        "        log_probs = logits.log_softmax(dim=2)    # CTC attend log-probas\n",
        "\n",
        "        loss = criterion(log_probs, targets_concat, input_lengths, target_lengths)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        if grad_clip is not None:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        running += loss.item()\n",
        "        if step % log_interval == 0:\n",
        "            avg = running / log_interval\n",
        "            print(f\"[epoch {epoch} step {step}] loss={avg:.4f}\")\n",
        "            running = 0.0\n",
        "\n",
        "            # Décodage rapide sur le mini-batch courant\n",
        "            with torch.no_grad():\n",
        "                preds = greedy_ctc_decode(log_probs.detach(), input_lengths)\n",
        "            # Affiche deux exemples\n",
        "            for i in range(min(2, len(preds))):\n",
        "                tgt = texts[i]\n",
        "                print(f\"  tgt: {tgt}\")\n",
        "                print(f\"  prd: {preds[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchcodec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ayZ6qj-dt9",
        "outputId": "ef08121a-cfb6-4e4d-b3a1-b5f640d65ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchcodec\n",
            "  Downloading torchcodec-0.8.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Downloading torchcodec-0.8.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchcodec\n",
            "Successfully installed torchcodec-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDej_ukDYYI8",
        "outputId": "74dbdc32-d1fc-4f02-a7be-4524e8a440c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 1 step 200] loss=3.1038\n",
            "  tgt: for some little time that is it seemed long though i believe it was not more than a minute before two men came running from the musicians gallery\n",
            "  prd: \n",
            "  tgt: i have always delighted in and reverenced beauty but i felt simply abashed in the presence of such a splendid type a compound of all that is best in egyptian greek and italian\n",
            "  prd: \n",
            "[epoch 2 step 200] loss=2.3716\n",
            "  tgt: the most gifted individuals in the land emulated each other in proving which entertained for him the most sincere affection\n",
            "  prd:  m n   s       r rs er\n",
            "  tgt: we've lost the key of the cellar and there's nothing out except water and i don't think you'd care for that\n",
            "  prd: ssns d    \n",
            "[epoch 3 step 200] loss=1.9733\n",
            "  tgt: on the tenth of october he would meet rod at sprucewood on the black sturgeon river\n",
            "  prd: o ian o re o mi s wis at onn he ucr er\n",
            "  tgt: a little longer and she was compelled to yield and the silent tears flowed freely\n",
            "  prd:  e mrin se wis om l l an te sa t is l rlyy\n",
            "[epoch 4 step 200] loss=1.7425\n",
            "  tgt: then back i turned my face to those high things which moved themselves towards us so sedately they had been distanced by new wedded brides\n",
            "  prd:  then bocatan t li aeto thos i s wit o en els oisas os etly thi a be dis o bio lat i rig\n",
            "  tgt: there was no poniard in the wound\n",
            "  prd: ther was no py rd in t\n",
            "[epoch 5 step 200] loss=1.6077\n",
            "  tgt: it was karl yundt who was heard implacable to his last breath\n",
            "  prd: i his ca od was hr an acebel to as less pre\n",
            "  tgt: they were run out of their village\n",
            "  prd: the r ontot of ther telenet\n",
            "[epoch 6 step 200] loss=1.5211\n",
            "  tgt: sufficient to make twelve buns seasonable at any time light buns\n",
            "  prd: sofiit to matt twa bans sason tapo ad eny tin lit oss\n",
            "  tgt: on the next day but one randal arranged his departure for sydenham so as to arrive at the hotel an hour before the time appointed for the dinner\n",
            "  prd: on te nexaa bot on randa loran is topartor rsinem sis t er ra a the o tolan ar be for the ta mapati fo teda\n",
            "[epoch 7 step 200] loss=1.4451\n",
            "  tgt: therefore i am a mere agent to direct the laws which are the will of the people and am only a public servant obliged constantly to guard the welfare of my subjects\n",
            "  prd: theer for i mo mer ygen to de rekthe las wih jr the wollo the pe an a mole u pulic ere oblied oed tatla to eri the lal terf my sactes\n",
            "  tgt: john mangles therefore hoped that the wretched hull would reach port without accident but it grieved him that his companions should have to suffer so much discomfort from the defective arrangements of the brig\n",
            "  prd: ga mg sr fr op thu r rec id o wadrit or wi thor at oin but i grave a ba hif co pannns ud hhet orssufer so mech is cofr fom the be ffe the rranemins of te bra\n",
            "[epoch 8 step 200] loss=1.3807\n",
            "  tgt: he tilted his head to look up\n",
            "  prd: he totfit tes ha to likop\n",
            "  tgt: but they'll put a man on for you\n",
            "  prd: but thel pot o man o ry\n",
            "[epoch 9 step 200] loss=1.3380\n",
            "  tgt: but in less than five minutes the staircase groaned beneath an extraordinary weight\n",
            "  prd: bute mosoi mans te stan cis grond ben nen y ctor nre wat\n",
            "  tgt: by the side of the door was constructed off hand by means of an empty barrel a box for the money taker who was sometimes fibi and sometimes vinos\n",
            "  prd: i the sitdaf te dor wast costrekdid oand by mengse o en emte beral a bosfor the my taer o wis on toms pebe an somtom spenos\n",
            "[epoch 10 step 200] loss=1.3083\n",
            "  tgt: yes he's mercurial in all his movements\n",
            "  prd: o as es mor corall e al hes mohme\n",
            "  tgt: that last fellow you had ought to have been tied up himself\n",
            "  prd: at lasstly ou ad otto av den titepem self\n",
            "[epoch 11 step 200] loss=1.2749\n",
            "  tgt: with the insight of a kindred temperament he pronounced his verdict\n",
            "  prd: witf thick in sit ot a cingo temperent he poams sts feri\n",
            "  tgt: he coughed drank his tea endeavoured to talk but found it difficult sometimes read and in this manner near two hours were passed away when miss milner came into the room not dressed for a ball but as she had risen from dinner\n",
            "  prd: he cok drank is t in dever o ap beanditit acls semdimds rati and i thi smada tarto u is woee hasdtowate win mis nohercimit o the ro tnhot dres fr abal tut ae she aresnfrormdener\n",
            "[epoch 12 step 200] loss=1.2261\n",
            "  tgt: but the prevailing doctrine of the eternity and inherent pravity of matter infected the primitive churches of the east\n",
            "  prd: bit th verthealindotrn o the etrnity annd hherad prata  ovf mater a fhac to the prematf turtis of byac\n",
            "  tgt: hilda watched him from her corner trembling and scarcely breathing dark shadows growing about her eyes\n",
            "  prd: ol te waso veom her cqoner tunmbelin and sceubretin tart caads gorin ta bou her s\n",
            "[epoch 13 step 200] loss=1.2143\n",
            "  tgt: accustomed as i had been to the steam ferry boats of the elbe i found the long oars of the boatmen but sorry means of locomotion\n",
            "  prd: a custond au aid bendo a tetrybut t ty al ba voung the lvorse the boin bt sorintlok omoion\n",
            "  tgt: if we decide to show mercy to this poor beggar it is not for you to oppose it\n",
            "  prd: if we the said  she morese to this porbager tas not fratwo asit\n",
            "[epoch 14 step 200] loss=1.1747\n",
            "  tgt: abandoned indeed by god and man almost\n",
            "  prd: at banden din ded by go and man a ost\n",
            "  tgt: from under the lining he now produced a collection of brilliantly colored paper figures several inches high and stiff enough to stand alone\n",
            "  prd: fenm undo the lining eno ode stocolllecton o broinly colode peater feusd sevrol ingis y and sto fe noftf  stin  lon\n",
            "[epoch 15 step 200] loss=1.1695\n",
            "  tgt: then they began to run and rushing into the house they fell upon their father's neck\n",
            "  prd: theyr teggantor ron and rarsign into ther hausthey fel upon ther oters na\n",
            "  tgt: the tribute was at this period enormous fifteen thousand head of cattle annually\n",
            "  prd: the crubed was at thes prad em normis chifte thuos and had of cadle hinaoly\n",
            "[epoch 16 step 200] loss=1.1366\n",
            "  tgt: the ladies\n",
            "  prd: the lais\n",
            "  tgt: you are to understand that catherine is a widow\n",
            "  prd: eu war tuundestand tha catrin is uwito\n",
            "[epoch 17 step 200] loss=1.1189\n",
            "  tgt: his progress from infancy to youth and manhood was marked by a regular increase in stature and wisdom and after a painful agony of mind and body he expired on the cross\n",
            "  prd: his proberisfromintansety yuf and manrd was marck byr reirin rece instatur an wis um and aftherpan fo adine of min aboty he ixpad on thecrous\n",
            "  tgt: then the shining of the wet leaves is delightful and the steamy fragrance and the burst of bird song from a multitude of thrushes and finches and warblers that have nests in the chaparral\n",
            "  prd: then the shonni of the wat las is the witfl an the spite fragres and te perst the brv son from a malttid of trusos an fincs and worblrs at avt nest son the shapera\n",
            "[epoch 18 step 200] loss=1.1036\n",
            "  tgt: the people must wait outside for there is no room for them in the palace\n",
            "  prd: the pepbl lust we osi fo ther s no rom firt them min the pise\n",
            "  tgt: go on down the mountain said mercury and as you go cast the bones of your mother over your shoulders behind you and with these words he leaped into the air and was seen no more\n",
            "  prd: go on down the motin sitd norturly and as you go cast the bones of you moter oer yur sho thers bein o and withthe is worrds he lept in dithy er and wic sg no oore\n",
            "[epoch 19 step 200] loss=1.0761\n",
            "  tgt: did they know of the existence of the prisoners or was it some private enterprise that led to the undertaking\n",
            "  prd: tet the not thexistn ofe the prisiners r was i som pive en apise that let  ganter cating\n",
            "  tgt: the heart of that ex convict was full of virginity\n",
            "  prd: thet har to ta ax convic was ful ofrginidy\n",
            "[epoch 20 step 200] loss=1.0758\n",
            "  tgt: his enthusiasm caused ursus to remark this man and gwynplaine to observe him\n",
            "  prd: his aths esemcosd orsus to e mark this man and gin plimed to a orve him\n",
            "  tgt: we did the same with physicians whom we often sent half dressed to some nobleman who was enjoying excellent health\n",
            "  prd: weu di the sa with fisitions o w aen sat haped drest to sumknobe len h was an doing isln help\n",
            "[epoch 21 step 200] loss=1.0490\n",
            "  tgt: saint paul is a saint only with extenuating circumstances\n",
            "  prd: sin pall is aant ally with xtenywating sur comsanes\n",
            "  tgt: some springs are so highly impregnated with salt as to have received the name of brine springs and are supposed to have become so by passing through the salt rocks below ground and thus dissolving a portion of this mineral substance\n",
            "  prd: son prinster se ily imprenadtof weh selt as e haver seev the mim of brin sprin and er so post traf be com sov bu passin tre te soll res blogroun and test tis oving a porth onf this ennal suex\n",
            "[epoch 22 step 200] loss=1.0471\n",
            "  tgt: under the same quiet moonlight and only six hundred yards away from us also lay the victorious rebel army\n",
            "  prd: on do thi seam ied  mon light and oly sic codrd yravsaway er mas alse lyvive tors reble ary\n",
            "  tgt: what should we have done if everybody had kept on burning wood to this day\n",
            "  prd: wi hd ra gon if avre body had capt bum burning od to hs by\n",
            "[epoch 23 step 200] loss=1.0286\n",
            "  tgt: the highest instinct for purity places him who is affected with it in the most extraordinary and dangerous isolation as a saint for it is just holiness the highest spiritualization of the instinct in question\n",
            "  prd: the is tinstint fo purde placees him whas afected wit it in the most xtrodna an dangrr is is latin asis aint vo is jus polinos th hies speirtelasatino they insin icusion\n",
            "  tgt: i told tom we shouldn't come so late says hilda\n",
            "  prd: i told tawa shhion comsoelaitsis ilda\n",
            "[epoch 24 step 200] loss=1.0103\n",
            "  tgt: the cuisine is of the best and the chefs rank at the top of their art\n",
            "  prd: the cusinis of the bess an the shaf ran o the top of ther art\n",
            "  tgt: he translated at an early age chiefly between eighteen forty five and eighteen forty nine a great number of poems by the italians contemporary with dante or preceding him and among other things he made a version of the whole vita nuova prose and verse\n",
            "  prd: he tranigdan at oor theand shef tlhiatween a tem forny fo innatemforti nim an gragteomber of cpoms y the atane ans contemeryf it tonta opriing him and omun oterthans he mane a vergon of the hol ve ton in o o phrose andfers\n",
            "[epoch 25 step 200] loss=1.0128\n",
            "  tgt: very characteristic perfectly typical\n",
            "  prd: bery carturest bevigly tipel\n",
            "  tgt: ursus was satisfied with the applause of southwark but by no means astonished\n",
            "  prd: ursus wat sadtis fied wit th applos o soutwerke but by no mens a stonish\n",
            "[epoch 26 step 200] loss=0.9940\n",
            "  tgt: that's funny remarked betsy thoughtfully\n",
            "  prd: thats fonyeremarkt bes se thagt uly\n",
            "  tgt: this is very good of you he began glancing down at the aged detective's bundled up legs and gently pushing a chair towards him\n",
            "  prd: this is veryg godtof ohe becand glaning gona the angd deten teves bondoe ub lags angeasl uieng a char t wordes hinm\n",
            "[epoch 27 step 200] loss=0.9933\n",
            "  tgt: presently it stole back to his coat sleeve\n",
            "  prd: brisant ly i sal bact ty his cops ee\n",
            "  tgt: and if you have time it would be a great service to translate the analyses of the poems which i omitted\n",
            "  prd: and iff yeo have time it wa beingrae serest a transliyt the a nal asees of the pon whih  imited\n",
            "[epoch 28 step 200] loss=0.9796\n",
            "  tgt: when the buzzer sounded he pulled his foil from his second's startled grasp and ran forward\n",
            "  prd: wo the buster sondeng he pod is llalf frorm is secan stare grast an gwrand forrd\n",
            "  tgt: let him out cried north again stamping his foot\n",
            "  prd: latenout crid north a gen staping his fut\n",
            "[epoch 29 step 200] loss=0.9762\n",
            "  tgt: as soon as ever of my second age i was upon the threshold and changed life himself from me he took and gave to others\n",
            "  prd: a so is everd of my seccina tit was apon the frecshold andctane lith himself from my he tok and gave to oters\n",
            "  tgt: jam exclaimed chunky stretching his neck and eyeing the dish longingly\n",
            "  prd: ja exping cunk stricghing his net and ing the dithhloningly\n",
            "[epoch 30 step 200] loss=0.9607\n",
            "  tgt: originally the most valuable of these were found in the spice islands or moluccas of the indian ocean and were highly prized by the nations of antiquity\n",
            "  prd: errginaly the most vabe o tese wer found in the sie siancs or mooes o te indyin otion a wer ily pris y the nations e anticidy\n",
            "  tgt: we should like above all things said deucalion to see this land full of people once more for without neighbors and friends the world is a very lonely place indeed\n",
            "  prd: we shoulvd lie o boal thanggs siddecanyin tosethis lin folif papple onse mr fo wis thout nabers anfrans te wor o is avery only placein dek\n",
            "[epoch 31 step 200] loss=0.9583\n",
            "  tgt: restless with impending joy he sauntered to the bridge and leant over the balustrade gazing on the waters in charmed and charming vacancy\n",
            "  prd: resslswufh inpen in jor he sonterd to brage and lend o vathe balstor gizsing on the wlaers ing cod and hhurmin vikecoy\n",
            "  tgt: sixty eight bishops twenty two of metropolitan rank defended his cause by a modest and temperate protest they were excluded from the councils of their brethren\n",
            "  prd: sextate bisuts twen e o wof mihhiopllusan rangke tofanist his cirs by m modest and tempret prtes thy wer explited fonthe centles wof ther bretheeren\n",
            "[epoch 32 step 200] loss=0.9601\n",
            "  tgt: for she had only the foundation laid criss cross as the magpie had shown her\n",
            "  prd: pershe had oloy the fomdation lad cris croes as the mank bi hav cshwn her\n",
            "  tgt: spring came and passed and then summer\n",
            "  prd: sprincanean pasd and then semer\n",
            "[epoch 33 step 200] loss=0.9486\n",
            "  tgt: but deucalion and pyrrha were very sad for they knew that they were the only persons who were left alive in all the land\n",
            "  prd: but da caain an pe wervery sad fo thy nt tat thaywear thy only perinns ho e left alive and al the lan\n",
            "  tgt: after reading one or two of the political articles he arrived at the columns specially devoted to fashionable intelligence\n",
            "  prd: after reeding oner to ovs the plitile latecles he r id that to coms spealy dobotet to fesin ob le inteligene\n",
            "[epoch 34 step 200] loss=0.9382\n",
            "  tgt: mode choose the greenest cucumbers and those that are most free from seeds put them in strong salt and water with a cabbage leaf to keep them down tie a paper over them and put them in a warm place till they are yellow then wash them and set them over the fire in fresh water with a very little salt and another cabbage leaf over them cover very closely but take care they do not boil\n",
            "  prd: mok sheuse the gren a ocumbers and thoes titer mos tfreefromes put theme and strong saltan water with acabad lef to kepem da ti hapaerer thom and put the mnta worm lace to ary yo then washe then and setthe or the fire infrechwatr wit ivary litile sel an and othe canly fof mhem comere very clustly te tak kari thy denoubi\n",
            "  tgt: that's it on your account\n",
            "  prd: thet sit wan ou recou\n",
            "[epoch 35 step 200] loss=0.9410\n",
            "  tgt: dear good god help us now she prayed\n",
            "  prd: dr gon go help as no she pred\n",
            "  tgt: her bare feet as if poked through the bottom of an unadorned sleeved calico sack buttoned tightly at neck and wrists felt over the rug for the slippers while she looked upward into her husband's face\n",
            "  prd: he bear fet as if pot to the botam oet ondajoncs ledd calile saick butn teviy at naccandres holt o it the rog fothe lecdrs l shebot ppperd enter hos en sface\n",
            "[epoch 36 step 200] loss=0.9354\n",
            "  tgt: when they are quite hot divide them lengthwise into three put some thin flakes of good butter between the slices press the rolls together and put them in the oven for a minute or two but not longer or the butter would oil take them out of the oven spread the butter equally over divide the rolls in half and put them on to a very hot clean dish and send them instantly to table\n",
            "  prd: when tmher puie hid devyvd them lint wiyse into ry puth som den lak of god buter be to in hs slices prist thea rolses to geter and pith ham an the ouvan foromminiderto but not longger or the butr whitdoil take te on of the outan spred the butter euly over i ie the rols in half and put thim on tooa very hupplain dase and sin them enctaclate totabl\n",
            "  tgt: it would have taken many knapsacks to hold all the gifts showered upon him by his friends and neighbors\n",
            "  prd: to wut etakeon many natsacti olda e get saared  qon h by his frence an nver\n",
            "[epoch 37 step 200] loss=0.9285\n",
            "  tgt: pop it's a course\n",
            "  prd: pap i's ecors\n",
            "  tgt: alexander slipped his arm about her\n",
            "  prd: all exender sfuck his arm otout her\n",
            "[epoch 38 step 200] loss=0.9314\n",
            "  tgt: doctor we all have our crosses have we not\n",
            "  prd: gocter we liw hav er crosses have rwe not\n",
            "  tgt: she asked minnie for ink and paper which were upon the mantel in the dining room and when the latter had gone to bed at ten got out drouet's card and wrote him\n",
            "  prd: he ask comany frt in an paper wich wer con the mantall i the inting wrom a en the latere had gontbata tand cout outras card a roe him\n",
            "[epoch 39 step 200] loss=0.9174\n",
            "  tgt: you will let me do it and in return i will marry you whenever you ask me answered christie sealing the promise with a kiss that silenced him\n",
            "  prd: lleou wile let ne tooit and inrtrine i lo mary wen ery wass mantrond cristy stein the promic with eces that und thhom\n",
            "  tgt: indeed if ever a general deserved honor grant had won it he had opened the mississippi to navigation and had captured nearly one hundred thousand prisoners and arms\n",
            "  prd: indat ifaver ajenre dosere oner grant at woneit he ad open the misosuppetonevigagtion and had paptured mearly on underd thous and prisners and rs\n",
            "[epoch 40 step 200] loss=0.9201\n",
            "  tgt: i am the one to go after walt if anyone has to i'll go down mister thomas\n",
            "  prd: hi am the on t e go efterwwallt if ei wound has te il go dion thistr touse\n",
            "  tgt: the boy hastened away and the manager fell to his musings\n",
            "  prd: the boy hasesan doway and themanger felto his masinggs\n",
            "[epoch 41 step 200] loss=0.9127\n",
            "  tgt: outside of these occasional reminders we could see no evidence of the desolation of the track of an invading army\n",
            "  prd: il sighd of thes apao rmindrs we ald se al avutene of the desilation  of the trak of an n vading army\n",
            "  tgt: mister shimerda went with him\n",
            "  prd: misse shomrrad a wect with him\n",
            "[epoch 42 step 200] loss=0.9176\n",
            "  tgt: but he stopped on the landing he had not the courage to again visit the death chamber\n",
            "  prd: but he stackond ilandin he had o the curage to gen bisir to det camber\n",
            "  tgt: randal wrote to accept the invitation determining to present himself before the appointed hour and to question catherine privately without giving her the advantage over him of preparing herself for the interview\n",
            "  prd: randold brot to ec cepthe intetaion dotrmining to pucentiself tefor the apited r and toestion cetren privently withouc giving her thvantaciver hamout propering her self for the in tho i\n",
            "[epoch 43 step 200] loss=0.9131\n",
            "  tgt: the sick man raged and shook his fist\n",
            "  prd: the sik man raged ted sholk cisfis\n",
            "  tgt: a loft under the arch of the roof contained the scenes and on opening a trap door lamps appeared producing wonders of light\n",
            "  prd: a lot inder the arc of the rove cuntane te sens and un ubining a trap do rlas uppard prodiing anders aflie\n",
            "[epoch 44 step 200] loss=0.9143\n",
            "  tgt: dear sir we beg to inform you that we are instructed to wait until to morrow thursday at one o'clock before filing suit against you on behalf of missus julia hurstwood for divorce and alimony\n",
            "  prd: deuser we bec ont foarnby ont thet waren stecpt to watentille mrld thrsty ad mone aclok te fore ilin sip en ento on be afod mises gul aersplid forat divrse and lonnoty\n",
            "  tgt: that evening an order came for us hamilton's division to assault the enemy's left flank at midnight\n",
            "  prd: that thevening an oor caime forus aviltensdindition to i salp thet enamas let flaktad mitlitt\n",
            "[epoch 45 step 200] loss=0.9036\n",
            "  tgt: in fact conformably to the slow rise of the democratic social order and its cause the blending of the blood of masters and slaves the originally noble and rare impulse of the masters to assign a value to themselves and to think well of themselves will now be more and more encouraged and extended but it has at all times an older ampler and more radically ingrained propensity opposed to it and in the phenomenon of vanity this older propensity overmasters the younger\n",
            "  prd: in factd confom e blay to the slorise of the dene cretxksxoumtrlorter andixs pos the blunding of the blod e meers a slased thy ar onolt knobot rr inpulls of the macters  wa sime a velou co themsels en to tink cwell of themsels will now bemore and mor an curage andextented thet at hasitaltime an older amplerend ma raticly inrained prpenity it a poose tot and on thet eomn a un obontitethis oller popinseteovermatrrst they ome\n",
            "  tgt: dante because virgilius has departed do not weep yet do not weep yet awhile for by another sword thou need'st must weep\n",
            "  prd: tonta becos vitulus is depited doo not we pat do not wep pyet  will forbya nother soor thou et mustt wep\n",
            "[epoch 46 step 200] loss=0.9043\n",
            "  tgt: i am not thinking about the garden mamma replied the young girl without lifting up her face we can plant new flowers and tie up even some of these afresh\n",
            "  prd: l no thinging a pout tha godand nmom we plid the en gro with ou blifting op per facse we conpetno florse and ti apbevhen some of tee af frishe\n",
            "  tgt: i became grotesquely anxious to assure him that indeed she and i had been as they say innocent throughout our last day together\n",
            "  prd: i be came grotesquly ingcios to isror him that ing ded she ad o hand bin asthey sy inecsentr out er lastkd tato gether\n",
            "[epoch 47 step 200] loss=0.8967\n",
            "  tgt: electronic equipment cascaded from the wall shelves and a heavy duty chain hoist came loose from its overhead track plunging to the floor with a terrifying crash\n",
            "  prd: el at tronicequient casd cate fro thbwil shels and a heavy oty chan hoee ctame lost ormmitsuver hed trac llanginto the for wih atearifing cras\n",
            "  tgt: he gave thanks for our food and comfort and prayed for the poor and destitute in great cities where the struggle for life was harder than it was here with us\n",
            "  prd: he geethaink pooer erfouoedand tcomfert and prate othe por ind dustetud ingre setes whi the stucl for ligfe whas hartry in awas her withes\n",
            "[epoch 48 step 200] loss=0.8953\n",
            "  tgt: i could not love thee dear so much loved i not honor more\n",
            "  prd: i could ot love ree ger si mah love thi not oermor\n",
            "  tgt: the first edition of erewhon sold in about three weeks i had not taken moulds and as the demand was strong it was set up again immediately\n",
            "  prd: the ferist o dition of eroon soldan ibout threewe i had not aken mols and as the devan was tron i was sad up agin amedinly\n",
            "[epoch 49 step 200] loss=0.9033\n",
            "  tgt: the second part begins here saying be now the third here then while it was his pleasure\n",
            "  prd: the suc on pert agin ere saing be now the thir here then walea was has qesture\n",
            "  tgt: all idealisation makes life poorer\n",
            "  prd: all idli satio make lifh ploor\n",
            "[epoch 50 step 200] loss=0.8939\n",
            "  tgt: next take either a large tablespoonful of brewer's yeast which has been rendered solid by mixing it with plenty of cold water and letting it afterwards stand to settle for a day and night or nearly an ounce of german yeast put it into a large basin and proceed to mix it so that it shall be as smooth as cream with three quarters pint of warm milk and water or with water only though even a very little milk will much improve the bread\n",
            "  prd: nextak ether alardge taals bon foul o gurses wich hes ben regered salad bamexing it with plety of cold water and lading it after word stan to satdtal forr day an nig or nerol an ountsovfe jurmman easts putit in to alarge ba in an pereed i mixit so te it halbeas mthis crin wittre quuater pite of ore nowk an water oor with hatder ally tho evein hevery litle meld whill mugh omproo the breid\n",
            "  tgt: he buried his biscuit under a layer of jam over which he spread a thick coating of honey\n",
            "  prd: he beried his bis kit underaly ov jan over woich i srit y thik comneg o hany\n"
          ]
        }
      ],
      "source": [
        "train_dataset = LIBRISPEECH(\"./data\", url=\"dev-clean\", download=True)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=8,                  # ajuster selon mémoire GPU/CPU\n",
        "    shuffle=True,\n",
        "    num_workers=4,                 # ajuster selon machine\n",
        "    collate_fn=collate_fn,\n",
        "    pin_memory=True if DEVICE.type == \"cuda\" else False,\n",
        ")\n",
        "\n",
        "num_classes = 1 + len(VOCAB)      # 0=blank + 1.. vocab\n",
        "model = BidirGRU_CTC(input_dim=N_MFCC, hidden_dim=128, num_classes=num_classes).to(DEVICE)\n",
        "criterion = nn.CTCLoss(blank=BLANK_ID, zero_infinity=True).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "epochs = 50   # commencer petit, augmenter ensuite\n",
        "for ep in range(1, epochs + 1):\n",
        "    train_one_epoch(model, train_loader, optimizer, criterion, ep, log_interval=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-E0F9-mjJbd"
      },
      "outputs": [],
      "source": [
        "def calculate_cer(predictions, targets):\n",
        "    \"\"\"Calcule le Character Error Rate\"\"\"\n",
        "    total_chars = 0\n",
        "    total_errors = 0\n",
        "\n",
        "    for pred, tgt in zip(predictions, targets):\n",
        "        errors = sum(1 for p, t in zip(pred, tgt) if p != t)\n",
        "        errors += abs(len(pred) - len(tgt))\n",
        "        total_errors += errors\n",
        "        total_chars += len(tgt)\n",
        "\n",
        "    return total_errors / max(total_chars, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujyqv8QF9flU"
      },
      "outputs": [],
      "source": [
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, input_lengths, targets_concat, target_lengths, texts in loader:\n",
        "            features = features.to(DEVICE)\n",
        "            input_lengths = input_lengths.to(DEVICE)\n",
        "            targets_concat = targets_concat.to(DEVICE)\n",
        "            target_lengths = target_lengths.to(DEVICE)\n",
        "\n",
        "            logits = model(features)\n",
        "            log_probs = logits.log_softmax(dim=2)\n",
        "            loss = criterion(log_probs, targets_concat, input_lengths, target_lengths)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Décodage pour CER\n",
        "            preds = greedy_ctc_decode(log_probs, input_lengths)\n",
        "            all_preds.extend(preds)\n",
        "            all_targets.extend(texts)\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    cer = calculate_cer(all_preds, all_targets)\n",
        "\n",
        "    return avg_loss, cer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7z9V_fhZ2lP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}