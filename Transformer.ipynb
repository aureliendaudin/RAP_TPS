{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "bSaXYjJUOqPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOsXyOYjOAnW"
      },
      "outputs": [],
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.emb = keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n",
        "\n",
        "\n",
        "class SpeechFeatureEmbedding(layers.Layer):\n",
        "    def __init__(self, num_hid=64, maxlen=100):\n",
        "        super().__init__()\n",
        "        self.conv1 = keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv2 = keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv3 = keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return self.conv3(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "OrynsljLOn_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.ffn_dropout = layers.Dropout(0.1)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
        "        ffn_out = self.ffn(enc_out_norm)\n",
        "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
        "        return ffn_out_norm"
      ],
      "metadata": {
        "id": "jIV3sGVlO06v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=64,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=10,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.target_maxlen = target_maxlen\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs):\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source)\n",
        "        y = self.decode(x, target)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input])\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "            loss = self.compute_loss(y=one_hot, y_pred=preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input])\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "        loss = self.compute_loss(y=one_hot, y_pred=preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source)\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ],
      "metadata": {
        "id": "btCqlxKSO4kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "pattern_wav_name = re.compile(r'([^/\\\\\\.]+)')\n",
        "\n",
        "keras.utils.get_file(\n",
        "    fname=\"data.tar.gz\",\n",
        "    origin=\"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n",
        "    extract=True,\n",
        "    archive_format=\"tar\",\n",
        "    cache_dir=\".\",\n",
        ")\n",
        "\n",
        "\n",
        "saveto = \"./datasets/data_extracted/LJSpeech-1.1\"\n",
        "wavs = glob(\"{}/**/*.wav\".format(saveto), recursive=True)\n",
        "\n",
        "id_to_text = {}\n",
        "with open(os.path.join(saveto, \"metadata.csv\"), encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        id = line.strip().split(\"|\")[0]\n",
        "        text = line.strip().split(\"|\")[2]\n",
        "        id_to_text[id] = text\n",
        "\n",
        "\n",
        "def get_data(wavs, id_to_text, maxlen=50):\n",
        "    \"\"\"returns mapping of audio paths and transcription texts\"\"\"\n",
        "    data = []\n",
        "    for w in wavs:\n",
        "        id = pattern_wav_name.split(w)[-4]\n",
        "        if len(id_to_text[id]) < maxlen:\n",
        "            data.append({\"audio\": w, \"text\": id_to_text[id]})\n",
        "    return data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD30xfoQO-uZ",
        "outputId": "223678e3-00d8-442b-c85f-1c0db1514f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "\u001b[1m2748572632/2748572632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorizeChar:\n",
        "    def __init__(self, max_len=50):\n",
        "        self.vocab = (\n",
        "            [\"-\", \"#\", \"<\", \">\"]\n",
        "            + [chr(i + 96) for i in range(1, 27)]\n",
        "            + [\" \", \".\", \",\", \"?\"]\n",
        "        )\n",
        "        self.max_len = max_len\n",
        "        self.char_to_idx = {}\n",
        "        for i, ch in enumerate(self.vocab):\n",
        "            self.char_to_idx[ch] = i\n",
        "\n",
        "    def __call__(self, text):\n",
        "        text = text.lower()\n",
        "        text = text[: self.max_len - 2]\n",
        "        text = \"<\" + text + \">\"\n",
        "        pad_len = self.max_len - len(text)\n",
        "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
        "\n",
        "    def get_vocabulary(self):\n",
        "        return self.vocab\n",
        "\n",
        "\n",
        "max_target_len = 200  # all transcripts in out data are < 200 characters\n",
        "data = get_data(wavs, id_to_text, max_target_len)\n",
        "vectorizer = VectorizeChar(max_target_len)\n",
        "print(\"vocab size\", len(vectorizer.get_vocabulary()))\n",
        "\n",
        "\n",
        "def create_text_ds(data):\n",
        "    texts = [_[\"text\"] for _ in data]\n",
        "    text_ds = [vectorizer(t) for t in texts]\n",
        "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
        "    return text_ds\n",
        "\n",
        "\n",
        "def path_to_audio(path):\n",
        "    # spectrogram using stft\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
        "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
        "    # normalisation\n",
        "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
        "    x = (x - means) / stddevs\n",
        "    audio_len = tf.shape(x)[0]\n",
        "    # padding to 10 seconds\n",
        "    pad_len = 2754\n",
        "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
        "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
        "    return x\n",
        "\n",
        "\n",
        "def create_audio_ds(data):\n",
        "    flist = [_[\"audio\"] for _ in data]\n",
        "    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n",
        "    audio_ds = audio_ds.map(path_to_audio, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return audio_ds\n",
        "\n",
        "\n",
        "def create_tf_dataset(data, bs=4):\n",
        "    audio_ds = create_audio_ds(data)\n",
        "    text_ds = create_text_ds(data)\n",
        "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
        "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
        "    ds = ds.batch(bs)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "\n",
        "split = int(len(data) * 0.99)\n",
        "train_data = data[:split]\n",
        "test_data = data[split:]\n",
        "ds = create_tf_dataset(train_data, bs=64)\n",
        "val_ds = create_tf_dataset(test_data, bs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBQYorC2PBem",
        "outputId": "b74226d8-c5e4-482e-e91c-a2c4841428ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DisplayOutputs(keras.callbacks.Callback):\n",
        "    def __init__(\n",
        "        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
        "    ):\n",
        "        \"\"\"Displays a batch of outputs after every epoch\n",
        "\n",
        "        Args:\n",
        "            batch: A test batch containing the keys \"source\" and \"target\"\n",
        "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
        "            target_start_token_idx: A start token index in the target vocabulary\n",
        "            target_end_token_idx: An end token index in the target vocabulary\n",
        "        \"\"\"\n",
        "        self.batch = batch\n",
        "        self.target_start_token_idx = target_start_token_idx\n",
        "        self.target_end_token_idx = target_end_token_idx\n",
        "        self.idx_to_char = idx_to_token\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        #if epoch % 5 != 0:\n",
        "        #    return\n",
        "        source = self.batch[\"source\"]\n",
        "        target = self.batch[\"target\"].numpy()\n",
        "        bs = tf.shape(source)[0]\n",
        "        preds = self.model.generate(source, self.target_start_token_idx)\n",
        "        preds = preds.numpy()\n",
        "        for i in range(bs):\n",
        "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
        "            prediction = \"\"\n",
        "            for idx in preds[i, :]:\n",
        "                prediction += self.idx_to_char[idx]\n",
        "                if idx == self.target_end_token_idx:\n",
        "                    break\n",
        "            print(f\"target:     {target_text.replace('-','')}\")\n",
        "            print(f\"prediction: {prediction}\\n\")"
      ],
      "metadata": {
        "id": "UL4-wd_CTByt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        init_lr=0.00001,\n",
        "        lr_after_warmup=0.001,\n",
        "        final_lr=0.00001,\n",
        "        warmup_epochs=15,\n",
        "        decay_epochs=85,\n",
        "        steps_per_epoch=203,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.init_lr = init_lr\n",
        "        self.lr_after_warmup = lr_after_warmup\n",
        "        self.final_lr = final_lr\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.decay_epochs = decay_epochs\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "\n",
        "    def calculate_lr(self, epoch):\n",
        "        \"\"\"linear warm up - linear decay\"\"\"\n",
        "        warmup_lr = (\n",
        "            self.init_lr\n",
        "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
        "        )\n",
        "        decay_lr = tf.math.maximum(\n",
        "            self.final_lr,\n",
        "            self.lr_after_warmup\n",
        "            - (epoch - self.warmup_epochs)\n",
        "            * (self.lr_after_warmup - self.final_lr)\n",
        "            / self.decay_epochs,\n",
        "        )\n",
        "        return tf.math.minimum(warmup_lr, decay_lr)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        epoch = step // self.steps_per_epoch\n",
        "        epoch = tf.cast(epoch, \"float32\")\n",
        "        return self.calculate_lr(epoch)"
      ],
      "metadata": {
        "id": "Pus6SXPcTCsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(val_ds))\n",
        "\n",
        "# The vocabulary to convert predicted indices into characters\n",
        "idx_to_char = vectorizer.get_vocabulary()\n",
        "display_cb = DisplayOutputs(\n",
        "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
        ")  # set the arguments as per vocabulary index for '<' and '>'\n",
        "\n",
        "model = Transformer(\n",
        "    num_hid=200,\n",
        "    num_head=2,\n",
        "    num_feed_forward=400,\n",
        "    target_maxlen=max_target_len,\n",
        "    num_layers_enc=4,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=34,\n",
        ")\n",
        "loss_fn = keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    label_smoothing=0.1,\n",
        ")\n",
        "\n",
        "learning_rate = CustomSchedule(\n",
        "    init_lr=0.00001,\n",
        "    lr_after_warmup=0.001,\n",
        "    final_lr=0.00001,\n",
        "    warmup_epochs=15,\n",
        "    decay_epochs=85,\n",
        "    steps_per_epoch=len(ds),\n",
        ")\n",
        "optimizer = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "\n",
        "history = model.fit(ds, validation_data=val_ds, callbacks=[display_cb], epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM30EbYtTF0d",
        "outputId": "7f474a13-1330-4381-d4a1-19819474036d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step - loss: 1.8477target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the the the or the on as the d a as t t tonthe the the the ale the on to on t he t a cate t aren then the t the ore nd athe the the t itin ore t e the the t an an on s ond at as ot a tian or s as te \n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <the the the or the on as the d a as t t tonthe the the the ale the on to on t he t a cate t aren then the t the ore nd athe the the t itin ore t e the the t alind on s ond at as ot a tian or s as te \n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <the the the or the on as the d a as t t tonthe the the the ale the on to on t he t a cate t aren then the t the ore nd athe the the t itin ore t e the the t an an on s ond at as ot a tian or s as te \n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <the the the or the on as the d a as t t tonthe the the the ale the on to on t he t a cate t aren then the t the ore nd athe the the t itin ore t e the the t an an on on ar at as ot a tian on s as te \n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 532ms/step - loss: 1.8468 - val_loss: 1.4650\n",
            "Epoch 2/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: 1.3882target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the the the the the the the the the the the the as the the the the the the the the the the the the an the the the the the the the the ore are on ore the terere therere ond athe the as athe the as te \n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <the the the the the the the the the the the the as the the the the the the the the the the the the an the the the the the the the the ore are on ore the te the there one the the on and an athe as te \n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <the the the the the the the the the the the the as the the the the the the the the the the the the an the the the the the the the the ore are on ore the te the there one the the on and an athe as te \n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <the the the the the the the the the the the the an the the the the the an the an the the an an the an the the the the there the the there are on ore the the an therere ond athe the and an athe as te \n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 441ms/step - loss: 1.3880 - val_loss: 1.3253\n",
            "Epoch 3/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: 1.3213target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the as the on the the the the the the the the the the the on the the the ore the the the the the the the the the of the the.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <the as the as the the as the the the the the the an an the an the the the as as an an the the as the the the the of an the the the the the of ofore.>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <the as the ore the the the the on the the the the the the of the the the on the ore the the on the as the on ore of are the the the ous.>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <the an the ore the the the the ore ore the the the the the the the the of the an the the ore the there.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 452ms/step - loss: 1.3212 - val_loss: 1.3037\n",
            "Epoch 4/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: 1.3053target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the the the the the ore the the the the the the of the the ore the the the the the the of ore ore the the of ore.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <the as the as the the as the the the as as as as and the an as and as and as and the the as and the an an an ond ane the and ore ane the the ande the.>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <the the the the the ore the the the the the the as the the ore the the as the are of the ore the the the the ore of the the the the ore the the the ore s.>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <the the the the the ore the the the the the the of the the ore the there ore there.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 449ms/step - loss: 1.3053 - val_loss: 1.2941\n",
            "Epoch 5/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: 1.2940target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the the the the the the the the the the the the fore the the fore the the the the fof the the fofore.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whe was the the the the the the the as an as the the the the fofofof the the as the the f the an the the the the the the the the fofof the the the the asine.>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <and the the the the of ofore the the the the the the the the of the the the the the the fore the the the the the ofore the fofof fof the the the the the the the.>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <sat the ore the the the the the the ore the the an the the ore the there ofofore.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 445ms/step - loss: 1.2940 - val_loss: 1.2705\n",
            "Epoch 6/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: 1.2659target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the far fais the the falle the fathe the fallle the fo the fane the the the fathe fathe the the the.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whe was the the fore the the the the the foswathe the the fore the the the fore the fore the fore fore f the the the foswallle f fore the alle the the.>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mast the sthe the wasthe the the the wan the wasthe fore the fore the the for the for the the asthe the the fo the the the fo the the fore the the the as.>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <sat was the troror was the the the wasasas was the the the wasasasas te.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 449ms/step - loss: 1.2658 - val_loss: 1.2335\n",
            "Epoch 7/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: 1.2249target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forte the fat the to the fay the the the to the the the the the to the the the the the to the the the the the the the>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while wh sorse the the the the the sisise fore the the the the the the the the the sisisisios of the the the the the the the osisiof tosion the the osiswale ton>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <he stat maste the the wo the the the stano the the the the fo sthe the the se formas the the the wore the the the the wo the o fore wor the the the wore the s>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <sat at was tre the wasas tre tre wasasatr and.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 444ms/step - loss: 1.2248 - val_loss: 1.1788\n",
            "Epoch 8/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: 1.1606target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the for the forse the fors the tat te the tat the tat t o the t the tat t o the t the tat o t o the>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while senctions of the the se considen of the the se consionswald ald and the t the t the ose of at oswald an ald an at at an at at atim ane on at oswandos on>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <not the stat tat the o the con the the server on the the ce for the t the o the ce for the t f the for the clor t the the f ce f f mar alour the the.>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <sat tried was trided was tried was tried, and and was and.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 448ms/step - loss: 1.1605 - val_loss: 1.0957\n",
            "Epoch 9/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: 1.0346target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the factection, but faction, but to of the tection, but to of the tection,>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whilifere had the neffections consions consions amposions ame the fections ame the fections ame the fections ampectininininintininininintectin>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <had band and ban the fire lone othe fire lone of the fire lon othe fir and the fir fired fired for and the fire fir an an an an lor lor lore lor lorore lore>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <sat lere for murder, and convied.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 456ms/step - loss: 1.0344 - val_loss: 0.9011\n",
            "Epoch 10/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.8839target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forger to of the gaing to of the gainged to of the gean tection,>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whileve of the nefectud oswere at the nefectud own seen fectube had nefectud own seempations at the nefectud one of se the the se the swe the the the sinse>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <and wor lone of the firm nothe firm nothe fir lone and the firm not the fire lone of the fire for lone and the for as, an the the the the as,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <sat ler was tried for murder, and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 465ms/step - loss: 0.8838 - val_loss: 0.8166\n",
            "Epoch 11/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.7978target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers of the gais of the gane tection, but fatection,>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whileve of ord his conse at the nefect of at the nefect on on ot his conse at the nefect on on ot his at the nefect on the the one one tuthe sithe onithe sithe ote sithithe>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mrs. and ward mrs. and word one as dential man age and word of a lone and word of a ward fach aremnis were lones,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <sat ler was trie for murder, and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 468ms/step - loss: 0.7977 - val_loss: 0.7730\n",
            "Epoch 12/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - loss: 0.7464target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the for took to overtifice is iscape over took to over took to over toof the gand detection.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whilvoourd his consimpatitue for suppors consimpatitue for seemport his not the neat neat for seemport his not oswald ald aldon ald aldone,>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. mr. mr. bad a service had bad bad bad bad bad bad bad bad bad bad bad an ward for lonest had bad bagent to the fofan fan fan fare far clor the fan fareren clofare thannnotennod then thenororororo\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <sat lere was trier, was trie was trie was trier, and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 468ms/step - loss: 0.7464 - val_loss: 0.7500\n",
            "Epoch 13/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - loss: 0.7151target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers alwais is is escape tection tection tection tection tection tection tection.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whileve oswald seemport his no down oswald seen for seen for seen for seen for support his no don oswald seen for see aly the the aly,>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mrs. the for loness are bas are bas are bas are bas are bas are bas are bas are bas a lonest had bas had bas are bas clon ar ar are the are ar ar are ar are.>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satil and convicted. and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 465ms/step - loss: 0.7151 - val_loss: 0.7185\n",
            "Epoch 14/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.6868target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the fordurs always but faction, but faction, but faction, but faction,>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whileve oswald seemport his not oswald simport his not hat the nead simport his not oswald seen for support his not he tiononoswatioswationonoswatectionong>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mrs. and ward for lonesservice had bas are lonest havicte had beential man agin as are lonestal man agin for loneser ar are aror ar the ar the>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <sat ride for murder was tried for murder, and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 463ms/step - loss: 0.6868 - val_loss: 0.6992\n",
            "Epoch 15/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.6535target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always is scalways is scalways is is scalways is is scalways is scalways is scaped over took to of gane.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whilevous considerations not doubt had irreatitud his port had irsport had irsport had iris port his not toward had inonononononononononononononon te>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. not the lone and was direm not the lone and contal man agin into the lone as revice had been to the firm not the farore ar are are n n then the n s,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satilure was tried for murder, and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 462ms/step - loss: 0.6535 - val_loss: 0.6567\n",
            "Epoch 16/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.6171target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always esscaped to tection, but faction, but faction,>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whilevose considerations no doubt had ireatitud his patitud out his pat the nead simpitud out had ireatitud his patituns t t t at t t t t at t t t alde>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <and was taken as are lone as remanagin to the firm notal managing and ward of lone as remanaging and aging clerk an as arken the arken arken then ark>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder was tried for murder was tried.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 462ms/step - loss: 0.6171 - val_loss: 0.6308\n",
            "Epoch 17/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: 0.5925target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always is scaped detection, but fate of the gang.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those considerations no oswald#s amily, it would seem that the neeffect on oswald#s at the nefect on oswald#s amonoswald ald aly>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mrs. bates had been cont alonging cont a longing cont a longing cont a longing cont a longing clark, and ward of a lon arofar ar are far ar ar ar ar ar arus,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder, and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 454ms/step - loss: 0.5925 - val_loss: 0.6088\n",
            "Epoch 18/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.5718target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the for took to over took to of gang. but fate over took to over took to over to of gan.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whileve ourt had simpith that the neat the neat the neat the neat the neat the neat the neffect oward had in a for suppos titit titititite,>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. baits had beential managing cont a the firm not a the firm not a lone as rervice, and ward for lown as rervice,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder, and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 465ms/step - loss: 0.5718 - val_loss: 0.6007\n",
            "Epoch 19/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: 0.5534target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the for took to of gang.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those considerations no doubt had in for suport had in for suport had seempitud house consideratitud house consid an ald an tin tin ald swan te>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. bates had been conto the firm not a lon as reward for long and ward for long and ward for longing cont a longing con far far far far se>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder, and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 455ms/step - loss: 0.5534 - val_loss: 0.5947\n",
            "Epoch 20/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - loss: 0.5393target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always escaped detection. but fate of gang.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those consideratitud seempitud seempithat the neffect on oswald#s attitud seempitud to had ineffect on oswald#s an titithe tititititititition>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. bates had beential man fates had beential man fates had been cont alone as arre ward for lone as arrough ard for lo far far far sen ce,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 454ms/step - loss: 0.5393 - val_loss: 0.5875\n",
            "Epoch 21/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.5266target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always always escaped to of the gang.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <whilevose considerations no doubth seem that the neffect on oswald#s ampethy, it would seem that the neffect on oswald se atithe atitit s atititititating>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. bates had been conf dential managinging conf dential managinging confidential managing conf dential man fates>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 462ms/step - loss: 0.5265 - val_loss: 0.5796\n",
            "Epoch 22/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: 0.5172target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always escapeded tection, but fate of gang.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those consideratitud seem that the neffect on oswald seem that the neffect on oswald#s atitud seem that the nefffect atit atitutititute,>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. bates had been cont alone as reward a for lone as reward a for lone as arward a for lone as arward a for long and for for ser for fisesese,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 455ms/step - loss: 0.5172 - val_loss: 0.5656\n",
            "Epoch 23/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.4993target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always escaped to of the gang.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those considerations no oswald#s amily, it would seem that the neet for suport and simpitud seem thatitud toward an efffect ort aneffect on ort suporthithe>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <and staken into the firm not along and was der a for lone as reward a for lown as reward a for lone as reward a for lowne as reward a for lonese,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 461ms/step - loss: 0.4993 - val_loss: 0.5361\n",
            "Epoch 24/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - loss: 0.4737target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always escaped detection, but fate of gang.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those considerations no doubt had in effect on oswald#s attitud had in effect on oswald#s at in effect on oswald#s no doswald#s amily>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <and wastaken and was taken in conthed a been conthed a been cont alown as arre ward a for lown as arre ward a for long as reward a for lown as>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 458ms/step - loss: 0.4737 - val_loss: 0.5304\n",
            "Epoch 25/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 0.4640target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always escapeded tection but fage detection, but fage detection, but fage detection.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those considerations no doubt had in effect on oswald#s at in effect on oswald#s atitude toward and simpethy,>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. bates taken incont along and westervice had been conthe firm not along and were ward a for lowng and firm not along and ward a for ward a for ward a forke ark.>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 474ms/step - loss: 0.4640 - val_loss: 0.5271\n",
            "Epoch 26/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - loss: 0.4530target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always escaped detection, but fate of gaing,>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those considerations no doubth suport his family, it would seempethy, it would seempethy it would seempethy, it would seempethy,>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. bates had been cont along and were ward a for long and westervice, and westervice, and were ward a for long and fathelerk, and ward a for long anot along as ark.>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 470ms/step - loss: 0.4530 - val_loss: 0.5271\n",
            "Epoch 27/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - loss: 0.4481target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always escaped detection, but faite of the gang,>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those considerations no doubt had aneffect on oswald#s atitude toward his family, it would seem that the neefffect on oswald#s attitude towere,>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. bates had been confed the firor lowng and faithl mr. bates had been conf dential menaging clork, and faithl mr. bates,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murter, and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 473ms/step - loss: 0.4481 - val_loss: 0.5169\n",
            "Epoch 28/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - loss: 0.4421target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always escaped detection, but fate of the gang.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those considerations no doubth simpely it would seem that the neffect oswald#s at it would seempethy, it would seem that the neffect on oswald#s atted simesithye,>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. not along and ward os taken and ward of lowng in fathl serviced had been conthe fathl own as reward a ward a ward a ward a ward atelown as>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 467ms/step - loss: 0.4421 - val_loss: 0.5122\n",
            "Epoch 29/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - loss: 0.4358target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always scaped detection, but faite over took too of the gan.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those considerations no doubt had ineffect on oswald#s atict onsiderations no doubt had ineffect on oswald#s aticuded oubthy,>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. bastervice had been conthed ancont a ward of long and whestervice, and whe and when as reward of lowng inclork, and wastervice,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 488ms/step - loss: 0.4358 - val_loss: 0.5152\n",
            "Epoch 30/30\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - loss: 0.4310target:     <the forgers always escaped detection. but fate overtook two of the gang,>\n",
            "prediction: <the forgers always escaped detection, but faite of the gang.>\n",
            "\n",
            "target:     <while those considerations no doubt had an effect on oswald#s attitude toward his family it would seem that the need for support and sympathy>\n",
            "prediction: <while those considerations no doubt had an effect on oswald#s atit would seem that the neffect on oswald#s atitude toward his family,>\n",
            "\n",
            "target:     <mr. bates had been confidential managing clerk, and was taken into the firm not alone as a reward for long and faithful service>\n",
            "prediction: <mr. bates taken and wstaken and whistaken and wstaken and ustaken an into the firm not the firm not the firm not the firm not all managing clork,>\n",
            "\n",
            "target:     <sattler was tried for murder and convicted#>\n",
            "prediction: <satler was tried for murder, and convicted.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 473ms/step - loss: 0.4310 - val_loss: 0.5147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOfWwYT7UNZv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}